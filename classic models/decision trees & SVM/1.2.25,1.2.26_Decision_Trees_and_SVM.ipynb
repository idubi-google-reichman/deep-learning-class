{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"127P3A88cvc164zwL6FOefZ6YCzTRk2Ea","timestamp":1719016542445}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Tutorial on Decision Trees and Support Vector Machines (SVM)\n","\n","In this tutorial, we will explore two powerful machine learning algorithms: Decision Trees and Support Vector Machines (SVM). We'll use Python's `sklearn` library to load datasets, train these models, and evaluate their performance."],"metadata":{"id":"H-IpQpX8KATC"}},{"cell_type":"code","source":["# Import necessary libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_wine\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load the dataset\n","data = load_wine()\n","X = data.data\n","y = data.target\n","\n","# # Output a brief overview of the dataset\n","# print(data.DESCR)\n","print(X.shape)\n","print(y.shape)\n","print(data['feature_names'])"],"metadata":{"id":"p2iqw9tqKBoS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"],"metadata":{"id":"EN9WSO96KU9B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Training\n","\n","### Decision Tree\n","\n","First, we will train a Decision Tree classifier.\n"],"metadata":{"id":"3KXruRF9Kbu0"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","\n","# Initialize the Decision Tree Classifier\n","dt_classifier = DecisionTreeClassifier(random_state=42,max_depth=2)\n","\n","# Train the classifier\n","dt_classifier.fit(X_train, y_train)"],"metadata":{"id":"Lt-i6KuKKak7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Let's try to visualize the decision tree classifier\n","from sklearn.tree import plot_tree\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(20,10))\n","plot_tree(dt_classifier, label='all', filled=True, feature_names=data.feature_names, class_names=data.target_names)\n","plt.show()"],"metadata":{"id":"NoHGOI2IKubz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SVM\n","\n","Next, we will train a Support Vector Machine (SVM)."],"metadata":{"id":"aEz6T6ZWKlNl"}},{"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","# Initialize the SVM Classifier\n","svm_classifier = SVC(random_state=42,kernel='linear')\n","\n","# Train the classifier\n","svm_classifier.fit(X_train, y_train)"],"metadata":{"id":"vzgf6-OCKgwU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation\n","\n","Now, let's evaluate the performance of our trained models on the test dataset.\n"],"metadata":{"id":"wOJ-pCsWKsTJ"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","def predict_and_evaluate_model(model,model_name,X_train,X_test,y_train,y_test):\n","  # Predict and evaluate the Decision Tree\n","  train_predictions = model.predict(X_train)\n","  train_accuracy = accuracy_score(y_train, train_predictions)\n","  print(f\"{model_name} Accuracy (Train set): {train_accuracy:2.6f}\")\n","\n","  test_predictions = model.predict(X_test)\n","  test_accuracy = accuracy_score(y_test, test_predictions)\n","  print(f\"{model_name} Accuracy (Test set): {test_accuracy:2.6f}\")\n","\n","predict_and_evaluate_model(dt_classifier,'Decision Tree',X_train,X_test,y_train,y_test)\n","print('--')\n","predict_and_evaluate_model(svm_classifier,'SVM',X_train,X_test,y_train,y_test)"],"metadata":{"id":"M1D1UQAOKoqi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["More on  *SVM*"],"metadata":{"id":"4vk1zxg_gd6W"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import svm\n","from sklearn.datasets import make_blobs\n","\n","# Step 1: Generate synthetic data\n","# Create 400 separable points\n","X, y = make_blobs(n_samples=400, centers=2, random_state=6)\n","\n","# Plot the data points\n","plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n","plt.xlabel('Feature 1')\n","plt.ylabel('Feature 2')\n","plt.title('Distribution of Synthetic Data Points')\n","plt.show()\n"],"metadata":{"id":"m685YRY0ZBmi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 2: Fit the model\n","# Fit the model, don't regularize for illustration purposes\n","clf = svm.SVC(kernel='linear', C=1000)\n","clf.fit(X, y)\n","\n","# Step 3: Plot the trained model's decision boundary\n","plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n","\n","# Draw the decision boundary\n","ax = plt.gca()\n","xlim = ax.get_xlim()\n","ylim = ax.get_ylim()\n","\n","# Create grid to evaluate model\n","xx = np.linspace(xlim[0], xlim[1], 30)\n","yy = np.linspace(ylim[0], ylim[1], 30)\n","YY, XX = np.meshgrid(yy, xx)\n","xy = np.vstack([XX.ravel(), YY.ravel()]).T\n","Z = clf.decision_function(xy).reshape(XX.shape)\n","\n","# Plot decision boundary and margins\n","ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n","\n","# Plot support vectors\n","ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n","           linewidth=1, facecolors='none', edgecolors='k')\n","plt.xlabel('Feature 1')\n","plt.ylabel('Feature 2')\n","plt.title('SVM Decision Boundary with Support Vectors')\n","plt.show()"],"metadata":{"id":"wGQ8ctAxgj35"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","\n","### ====================================== Exercise ======================================\n","# 1. Load the Iris dataset from sklearn. Use the `data`, and `target` variables from the dataset to train classifiers\n","# 2. Split the data to train and test using 70%-30% split\n","# 3. Train a decision tree classifier (with default parameters)\n","# 4. Train an SVM (with default parameters)\n","# 5. Test the performance of both models using accuracy_score\n","\n","iris = load_iris()"],"metadata":{"id":"JM3r9v6lhICA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NjeNlzGmBj8O"},"execution_count":null,"outputs":[]}]}